{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask 3: Persuasion Techniques Detection\n",
    "\n",
    "## Description\n",
    "Given a news article, identify the persuasion techniques in each paragraph. This is a multi-label task at paragraph level.\n",
    "Multiple languages are available for this task, and label scheme is hierarchical, with 6 broader categories subdivided into\n",
    "23 fine-grained categories. The number of techniques per language may vary slightly. A paragraph can have N simultaneous\n",
    "persuasion techniques.\n",
    "\n",
    "Input data will be sentences from news and web articles in plain text format. Templates for sentence numbers in each\n",
    "article were provided. Articles were collected from 2020 to mid 2022 and revolve around fixed range of topics such as\n",
    "COVID-19, climate change, migration, the war on Ukraine and country-specific local events such as elections. Large\n",
    "fraction of articles were identified by fract-checkers and experts. Titles are always on paragraph 1, if they exist,\n",
    "then a blank line separates it from the rest of the article body. Spans for annotated parts characterizing the label\n",
    "inside the paragraph are also provided.\n",
    "\n",
    "## Submission\n",
    "Official measure is micro-F1 computed using the 23 fine-grained labels. THe coarse-grained labels will also be evaluated\n",
    "and communicated to the participating teams.\n",
    "\n",
    "## Dates\n",
    "* January 12, 2023 - Release of test set\n",
    "* January 22, 2023 - Test submission site closes\n",
    "* February 2023 - Paper submission Deadline\n",
    "\n",
    "\n",
    "## Labels\n",
    "Persuasive text is characterized by a specific use of language in order to influence readers. We\n",
    "distinguishes the following high level 6 approaches: Justification, Simplification, Distraction,\n",
    "Call, Attack on Reputation and Manipulative Wording.\n",
    "\n",
    "* **Justification**: an argument made of two parts is given: a statement + justification.\n",
    "  \n",
    "* **Simplification**: a statement is made that excessively simplify a problem, usually regarding\n",
    "the cause, the consequence or the existence of choices.\n",
    "\n",
    "* **Distraction**: a statement is made that changes the focus away from the main topic or argument.\n",
    "  \n",
    "* **Call**: the text is not an argument but an encouragement to act or think in a particular way.\n",
    "  \n",
    "* **Manipulative wording**: a statement is made that is not an argument or specific language\n",
    "is used, which contains words/phrases that are either non-neutral, confusing, exaggerating,\n",
    "loaded, etc., in order to impact the reader, for instance emotionally.\n",
    "\n",
    "* **Attack on reputation**: an argument whose object is not the topic of the conversation,\n",
    "but the personality of a participant, his experience and deeds, typically in order to question\n",
    "and/or undermine his credibility. The object of the argumentation can also refer to a group\n",
    "of individuals, organization, or an activity.\n",
    "  * **Name Calling or Labelling**: Typically used in an *insulting* or demanding way. Labelling an object as something the\n",
    "  target audience fears, hates, etc. Calls for a qualitative judgement that disregards facts and focus on the subject.\n",
    "  Is *similar to manipulative wording*. What distinguishes it from Loaded Language is that it is only concerned about\n",
    "  the characterization of the subject.\n",
    "\n",
    "    Example: \"**’Fascist’ Anti-Vax** Riot Sparks COVID Outbreak in Australia.\"\n",
    "\n",
    "  * **Guilt by association**: Associating the subject with another things with negative connotations. Difference\n",
    "  between this and Name calling is that this requires an **association** while Name calling simply uses the insult word.\n",
    "\n",
    "    Example: \"**Do you know who else was doing that ? Hitler!**”\n",
    "\n",
    "  * **Casting Doubt**: Tries to discredit something by raising questions.\n",
    "\n",
    "    Example: \"A candidate talks about his opponent and says: **Is he ready to be the Mayor?**”\n",
    "\n",
    "  * **Appeal to Hypocrisy**: Criticizing someone for something you did. This is related to Whataboutism, but this attacks\n",
    "    the target directly, while Whataboutism focuses on the topic. This can also be seen as a specific type of Casting Doubt.\n",
    "\n",
    "    Example: How can you demand that I eat less meat to reduce my carbon footprint if you yourself drive\n",
    "    a big SUV and fly for holidays to Bali?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import make_dataframe\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\"en\", \"fr\", \"ge\", \"it\", \"po\", \"ru\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = pd.DataFrame(), pd.DataFrame()\n",
    "for lang in languages:\n",
    "    train_folder = f\"../data/{lang}/train-articles-subtask-3/\"\n",
    "    dev_folder = f\"../data/{lang}/dev-articles-subtask-3/\"\n",
    "    labels_file = f\"../data/{lang}/train-labels-subtask-3.txt\"\n",
    "\n",
    "    aux_train = make_dataframe(train_folder, labels_file)\n",
    "    aux_train[\"lang\"] = lang\n",
    "\n",
    "    aux_test = make_dataframe(dev_folder)\n",
    "    aux_test[\"lang\"] = lang\n",
    "\n",
    "    train_df = pd.concat([train_df, aux_train], ignore_index=True)\n",
    "    test_df = pd.concat([test_df, aux_test], ignore_index=True)\n",
    "\n",
    "    # out_folder = f\"../results/result-subtask3-dev-{lang}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_count = (\n",
    "    train_df[[\"labels\", \"lang\"]]\n",
    "        .apply(lambda x: (x[\"labels\"].split(\",\"), x[\"lang\"]), axis=1, result_type=\"broadcast\")\n",
    "        .explode(\"labels\")\n",
    ")\n",
    "\n",
    "labels = train_labels_count[\"labels\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label Count\")\n",
    "train_labels_count.groupby([\"labels\"]).count().sort_values(by=\"lang\", ascending=False).plot(kind=\"bar\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/label_counts.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Count of label ocurrence for each language.\")\n",
    "train_labels_count.groupby([\"lang\"]).count().sort_values(by=\"labels\", ascending=False).plot(kind=\"bar\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/language_counts.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"English is missing 4 labels:\")\n",
    "missing_labels = set(labels).difference(set(train_labels_count[train_labels_count[\"lang\"] == \"en\"][\"labels\"].unique()))\n",
    "for lbl in missing_labels:\n",
    "    print(\"-\", lbl)\n",
    "train_labels_count.groupby(\"lang\").nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_biggest_df = pd.DataFrame(columns=[\"label\", \"lang\"])\n",
    "for lbl in labels:\n",
    "    lang_counts = train_labels_count[train_labels_count[\"labels\"] == lbl][\"lang\"].value_counts()\n",
    "    lang = lang_counts.index[0]\n",
    "\n",
    "    count_biggest_df = pd.concat([count_biggest_df, pd.DataFrame({\"label\": [lbl], \"lang\": [lang]})], ignore_index=True)\n",
    "\n",
    "print(\"Which language has the highest number of examples for each label?\")\n",
    "count_biggest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rank of languages with highest number of samples per label.\")\n",
    "count_biggest_df.groupby(\"lang\").agg({\"lang\": \"count\", \"label\": lambda x: list(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7.5))\n",
    "# train_labels_count.plot(kind=\"bar\")\n",
    "sorted_categories = train_labels_count.groupby([\"labels\"]).count().sort_values(by=\"lang\", ascending=False).index\n",
    "sns.countplot(data=train_labels_count, x=\"labels\", hue=\"lang\", order=sorted_categories)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/label_counts_by_language.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Co-occurence matrix: each cell represents the ratio of co-ocurrence of label i with label j. Rows sum to 100%.\")\n",
    "plt.figure(figsize=(10,8))\n",
    "labels = train_df[\"labels\"].apply(lambda x: x.split(\",\")).explode().unique()\n",
    "\n",
    "co_ocurrences = {}\n",
    "for label in labels:\n",
    "    co_ocurrences[label] = dict.fromkeys(labels, 0)\n",
    "    example_labels_df = train_df[\"labels\"].apply(lambda x: x.split(\",\"))\n",
    "    for row in example_labels_df:\n",
    "        if label in row:\n",
    "            for lbl in row:\n",
    "                co_ocurrences[label][lbl] += 1\n",
    "\n",
    "coo_occurence_matrix = np.zeros((len(labels), len(labels)))\n",
    "label_mapping = {label: idx for label, idx in zip(labels, range(len(labels)))}\n",
    "count_map = {v: k for k,v in train_labels_count[\"labels\"].to_dict().items()}\n",
    "for lbl_i, aux in co_ocurrences.items():\n",
    "    for lbl_j, count in aux.items():\n",
    "        i = label_mapping[lbl_i]\n",
    "        j = label_mapping[lbl_j]\n",
    "        if i != j:\n",
    "            coo_occurence_matrix[i][j] = count/np.sum(sorted(list(aux.values()))[:-1])\n",
    "\n",
    "sns.heatmap(coo_occurence_matrix, xticklabels=labels, yticklabels=labels)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/class_cooccurrence.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"What is the ratio between train and development sets for each language?\")\n",
    "aux_test = test_df[[\"lang\"]]\n",
    "aux_test[\"split\"] = \"test\"\n",
    "\n",
    "aux_train = train_labels_count[[\"lang\"]]\n",
    "aux_train[\"split\"] = \"train\"\n",
    "\n",
    "aux_df = pd.concat([aux_train, aux_test], axis=0)\n",
    "sns.countplot(data=aux_df, x=\"lang\", hue=\"split\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/train_vs_dev_langs.jpeg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('semeval2023task3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef8d45cd79d7eaa49beae52470ad882584d4871e76f1b2182764299f298b656b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
