{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from utils import make_dataframe, save_results\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report as report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "SEED = 10\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_size):\n",
    "    indices = df.index.levels[0]\n",
    "    train_idxs = np.random.choice(indices, size=int(len(indices)*train_size), replace=False)\n",
    "    dev_idxs = np.setdiff1d(indices, train_idxs)\n",
    "\n",
    "    train_df = df[np.in1d(df.index.get_level_values(0), train_idxs)]\n",
    "    test_df = df[np.in1d(df.index.get_level_values(0), dev_idxs)]\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\"en\", \"fr\", \"ge\", \"it\", \"po\", \"ru\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = pd.DataFrame()\n",
    "artifacts = dict.fromkeys(languages, None)\n",
    "for lang in languages:\n",
    "    train_folder = f\"../data/{lang}/train-articles-subtask-3/\"\n",
    "    dev_folder = f\"../data/{lang}/dev-articles-subtask-3/\"\n",
    "    labels_file = f\"../data/{lang}/train-labels-subtask-3.txt\"\n",
    "\n",
    "    test_df = make_dataframe(dev_folder)\n",
    "    train_df = make_dataframe(train_folder, labels_file)\n",
    "\n",
    "    # split train into train and dev\n",
    "    train_df, dev_df = train_test_split(train_df, train_size=0.7)\n",
    "\n",
    "    X_train = train_df[\"text\"].values\n",
    "    y_train = train_df[\"labels\"].str.split(\",\").values\n",
    "\n",
    "    X_dev = dev_df[\"text\"].values\n",
    "    y_dev = dev_df[\"labels\"].str.split(\",\").values\n",
    "\n",
    "    multibin = MultiLabelBinarizer()\n",
    "    y_train = multibin.fit_transform(y_train)\n",
    "    y_dev = multibin.transform(y_dev)\n",
    "\n",
    "    pipe = Pipeline([('vectorizer',CountVectorizer(ngram_range = (1, 3), \n",
    "                                               analyzer='word')),\n",
    "                ('SVM_multiclass', MultiOutputClassifier(svm.SVC(class_weight= None,C=1, kernel='linear'),n_jobs=1))])\n",
    "\n",
    "    pipe.fit(X_train,y_train)\n",
    "\n",
    "    print(f'{lang}: In-sample Acc: \\t\\t', pipe.score(X_dev, y_dev))\n",
    "\n",
    "    \n",
    "    y_pred_transform = pipe.predict(X_dev)\n",
    "    y_pred = [\",\".join(x) for x in multibin.inverse_transform(y_pred_transform)]\n",
    "\n",
    "    dev_df[\"labels_pred\"] = y_pred\n",
    "    dev_df.loc[:, \"y_true\"] = y_dev.tolist()\n",
    "    dev_df.loc[:, \"y_pred\"] = y_pred_transform.tolist() \n",
    "    dev_df[\"lang\"] = lang\n",
    "\n",
    "    baseline_df = pd.concat([baseline_df, dev_df], ignore_index=True)\n",
    "\n",
    "    artifacts[lang] = {\"model\": pipe, \"binarizer\": multibin}\n",
    "    # out_folder = f\"../results/result-subtask3-dev-{lang}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "metrics_df = pd.DataFrame()\n",
    "\n",
    "for lang in languages:\n",
    "    binarizer = artifacts[lang][\"binarizer\"]\n",
    "    lang_df = baseline_df[baseline_df[\"lang\"] == lang]\n",
    "    y_true = np.stack(lang_df[\"y_true\"].apply(np.array).to_numpy())\n",
    "    y_pred = np.stack(lang_df[\"y_pred\"].apply(np.array).to_numpy())\n",
    "    \n",
    "    metric_f1micro = f1_score(y_true, y_pred, average=\"micro\")\n",
    "    metric_f1macro = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    metric_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    aux_df = pd.DataFrame({\"f1-micro\": [metric_f1micro], \"f1-macro\": [metric_f1macro], \"accuracy\": [metric_acc]}, index=[lang])\n",
    "    metrics_df = pd.concat([metrics_df, aux_df])\n",
    "    print(lang)\n",
    "    print(classification_report(y_true, y_pred, target_names=binarizer.classes_))\n",
    "    \n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings\n",
    "* Italian did best because of the Doubt class, in which Italian has the most number of samples than any other language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = multibin.inverse_transform(Y_pred)\n",
    "out = list(map(lambda x: ','.join(x), out))\n",
    "out = pd.DataFrame(out, test_df.index)\n",
    "out.to_csv(out_folder, sep='\\t', header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('semeval2023task3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef8d45cd79d7eaa49beae52470ad882584d4871e76f1b2182764299f298b656b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
